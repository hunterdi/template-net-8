services:
    postgres:
        image: postgres:16.4-bullseye
        restart: unless-stopped
        # user: root
        environment:
            POSTGRES_PASSWORD: 12369
        ports:
            - 15432:5432
        volumes:
            - ./Data/postgreSQL:/var/lib/postgresql/data

    azurite:
        image: mcr.microsoft.com/azure-storage/azurite
        hostname: azurite
        restart: unless-stopped
        command: "azurite --loose --blobHost 127.0.0.1 --blobPort 10000 --queueHost 127.0.0.1 --queuePort 10001 --tableHost 127.0.0.1 --tablePort 10002 --location /workspace --debug /workspace/debug.log"
        ports:
            - 10000:10000
            - 10001:10001
            - 10002:10002
        volumes:
           - ./Data/storage:/workspace

    seq:
        image: datalust/seq:2024
        restart: unless-stopped
        ports:
          - 80:80
          - 5341:5341
        environment:
          ACCEPT_EULA: Y
          
    zookeeper:
        image: confluentinc/cp-zookeeper:7.7.0
        container_name: zookeeper
        restart: unless-stopped
        # user: root
        ports:
            - 2181:2181
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
            KAFKA_JMX_PORT: 9101
        healthcheck:
            test: echo srvr | nc zookeeper 2181 || exit 1
            interval: 10s
            timeout: 10s
            retries: 3
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    broker-1:
        image: confluentinc/cp-kafka:7.7.0
        container_name: broker-1
        restart: unless-stopped
        # user: root
        ports:
            - 9091:9091
            - 9101:9101
        depends_on:
            - zookeeper
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-1:29091,EXTERNAL://localhost:9091
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_JMX_PORT: 9101
            KAFKA_JMX_HOSTNAME: localhost
            KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            KAFKA_DEFAULT_REPLICATION_FACTOR: 3
            KAFKA_NUM_PARTITIONS: 3
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
        healthcheck:
            test: nc -vz localhost 9091
            interval: 10s
            timeout: 10s
            retries: 3
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    broker-2:
        image: confluentinc/cp-kafka:7.7.0
        container_name: broker-2
        restart: unless-stopped
        # user: root
        ports:
            - 9092:9092
            - 9102:9101
        depends_on:
            - zookeeper
        environment:
            KAFKA_BROKER_ID: 2
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-2:29092,EXTERNAL://localhost:9092
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_JMX_PORT: 9101
            KAFKA_JMX_HOSTNAME: localhost
            KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            KAFKA_DEFAULT_REPLICATION_FACTOR: 3
            KAFKA_NUM_PARTITIONS: 3
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
        healthcheck:
            test: nc -vz localhost 9092
            interval: 10s
            timeout: 10s
            retries: 3
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    broker-3:
        image: confluentinc/cp-kafka:7.7.0
        container_name: broker-3
        restart: unless-stopped
        # user: root
        ports:
            - 9093:9093
            - 9103:9101
        depends_on:
            - zookeeper
        environment:
            KAFKA_BROKER_ID: 3
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-3:29093,EXTERNAL://localhost:9093
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_JMX_PORT: 9101
            KAFKA_JMX_HOSTNAME: localhost
            KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            KAFKA_DEFAULT_REPLICATION_FACTOR: 3
            KAFKA_NUM_PARTITIONS: 3
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
        healthcheck:
            test: nc -vz localhost 9093
            interval: 10s
            timeout: 10s
            retries: 3
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    schema-registry:
        image: confluentinc/cp-schema-registry:7.7.0
        ports:
            - 8081:8081
        container_name: schema-registry
        restart: unless-stopped
        # user: root
        depends_on:
            - zookeeper
            - broker-1
            - broker-2
            - broker-3
        environment:
            SCHEMA_REGISTRY_HOST_NAME: schema-registry
            SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://broker-1:29091,PLAINTEXT://broker-2:29092,PLAINTEXT://broker-3:29093
            SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: 300
            
    ksqldb-server:
        image: confluentinc/ksqldb-server:0.29.0
        hostname: ksqldb
        container_name: ksqldb
        restart: unless-stopped
        # user: root
        depends_on:
            - broker-1
            - broker-2
            - broker-3
        ports:
            - 8088:8088
        environment:
            KSQL_LISTENERS: http://0.0.0.0:8088
            KSQL_BOOTSTRAP_SERVERS: broker-1:29091,broker-2:29092,broker-3:29093
            KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
            KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
            KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            KSQL_KSQL_SERVICE_ID: confluent_rmoff_01
            KSQL_KSQL_HIDDEN_TOPICS: ^_.*
            KSQL_KSQL_CONNECT_WORKER_CONFIG: /connect/connect.properties
            KSQL_CONNECT_BOOTSTRAP_SERVERS: broker-1:29091,broker-2:29092,broker-3:29093
            KSQL_CONNECT_REST_ADVERTISED_HOST_NAME: ksqldb
            KSQL_CONNECT_GROUP_ID: ksqldb-kafka-connect-group-01
            KSQL_CONNECT_CONFIG_STORAGE_TOPIC: _ksqldb-kafka-connect-group-01-configs
            KSQL_CONNECT_OFFSET_STORAGE_TOPIC: _ksqldb-kafka-connect-group-01-offsets
            KSQL_CONNECT_STATUS_STORAGE_TOPIC: _ksqldb-kafka-connect-group-01-status
            KSQL_CONNECT_KEY_CONVERTER: org.apache.kafka.connect.converters.IntegerConverter
            KSQL_CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
            KSQL_CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            KSQL_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '1'
            KSQL_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '1'
            KSQL_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '1'
            KSQL_CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: '[%d] %p %X{connector.context}%m (%c:%L)%n'
            KSQL_CONNECT_PLUGIN_PATH: /usr/share/java,/data/connect-jars
        command:
            - /bin/bash
            - -c
            - |
              echo "Launching ksqlDB"
              /usr/bin/docker/run &
              #
              sleep infinity

    ksqldb-cli:
        image: confluentinc/ksqldb-cli:0.29.0
        container_name: ksqldb-cli
        restart: unless-stopped
        # user: root
        depends_on:
            - broker-1
            - broker-2
            - broker-3
            - ksqldb-server
        entrypoint: /bin/sh
        tty: true
        environment:
            KSQL_CONFIG_DIR: /etc/ksql

    connect:
        image: confluentinc/cp-kafka-connect:7.7.0
        hostname: connect
        container_name: connect
        restart: unless-stopped
        # user: root
        depends_on:
            - zookeeper
            - broker-1
            - broker-2
            - broker-3
            - schema-registry
        ports:
            - 8083:8083
        environment:
            CONNECT_BOOTSTRAP_SERVERS: broker-1:29091,broker-2:29092,broker-3:29093
            CONNECT_REST_ADVERTISED_HOST_NAME: connect
            CONNECT_REST_PORT: 8083
            CONNECT_GROUP_ID: compose-connect-group
            CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
            CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/etc/connect-jars
            CONNECT_AUTO_CREATE_TOPICS_ENABLE: "true"
            CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
            CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
            CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
            CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
            CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
            CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
            CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
            CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
            CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
            CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
            CONNECT_ZOOKEEPER_CONNECT: zookeeper:2181
        volumes:
            - ./Data/kafka-connect:/etc/kafka-connect/jars
            - ./Data/connect/java:/usr/share/confluent-hub-components
        command:
            - bash
            - -c
            - |
              echo "Installing Connector"
              confluent-hub install --no-prompt confluentinc/kafka-connect-datagen:0.6.4
              confluent-hub install --no-prompt mongodb/kafka-connect-mongodb:1.11.0
              confluent-hub install --no-prompt debezium/debezium-connector-mongodb:2.2.1
              confluent-hub install --no-prompt debezium/debezium-connector-postgresql:2.2.1 
              confluent-hub install --no-prompt debezium/debezium-connector-mysql:2.2.1
              confluent-hub install --no-prompt debezium/debezium-connector-sqlserver:2.2.1
              confluent-hub install --no-prompt confluentinc/kafka-connect-azure-blob-storage-source:2.5.7
              confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:14.0.10
              confluent-hub install --no-prompt dariobalinzo/kafka-connect-elasticsearch-source:1.5.5
              confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.7.4
              confluent-hub install --no-prompt confluentinc/kafka-connect-rabbitmq-sink:1.7.9
              confluent-hub install --no-prompt confluentinc/kafka-connect-mqtt:1.7.0
              confluent-hub install --no-prompt confluentinc/kafka-connect-rabbitmq:1.7.9
              confluent-hub install --no-prompt confluentinc/kafka-connect-azure-blob-storage:1.6.16
              confluent-hub install --no-prompt jcustenborder/kafka-connect-redis:0.0.5
              confluent-hub install --no-prompt confluentinc/kafka-connect-json-schema-converter:7.5.0
              confluent-hub install --no-prompt confluentinc/kafka-connect-avro-converter:7.5.0
              #
              echo "Launching Kafka Connect worker"
              /etc/confluent/docker/run &
              #
              sleep infinity

    # rest-proxy:
    #     image: confluentinc/cp-kafka-rest:7.7.0
    #     hostname: rest-proxy
    #     container_name: rest-proxy
    #     restart: unless-stopped
    #     depends_on:
    #         - zookeeper
    #         - broker-1
    #         - broker-2
    #         - broker-3
    #         - schema-registry
    #     ports:
    #         - 8082:8082
    #     environment:
    #         KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
    #         KAFKA_REST_LISTENERS: 'http://0.0.0.0:8082'
    #         KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
    #         KAFKA_REST_HOST_NAME: rest-proxy
    #         KAFKA_REST_BOOTSTRAP_SERVERS: PLAINTEXT://broker-1:29091,PLAINTEXT://broker-2:29092,PLAINTEXT://broker-3:29093

    kafka-ui: 
        container_name: kafka-ui 
        image: provectuslabs/kafka-ui:v0.7.2
        restart: unless-stopped
        # user: root
        ports:
            - 8090:8080
        depends_on:
            - broker-1
            - broker-2
            - broker-3
            - connect
            - schema-registry
        environment:
            KAFKA_CLUSTERS_0_NAME: brokers
            KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker-1:29091,broker-2:29092,broker-3:29093
            KAFKA_CLUSTERS_0_METRICS_PORT: 9101
            KAFKA_CLUSTERS_0_SCHEMAREGISTRY: 'http://schema-registry:8081'
            KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
            DYNAMIC_CONFIG_ENABLED: 'true'
        logging:
            driver: "json-file"
            options:
                max-size: "1m"

    rabbitmq:
        image: rabbitmq:management
        container_name: rabbitmq
        restart: unless-stopped
        # user: root
        ports:
            - 5672:5672
            - 15672:15672
        volumes:
            - ./Data/rabbitmq/data/:/var/lib/rabbitmq/
            - ./Data/rabbitmq/log/:/var/log/rabbitmq

    prometheus:
        image: prom/prometheus:v2.53.2
        container_name: prometheus
        hostname: prometheus
        restart: unless-stopped
        ports:
          - 9090:9090
        volumes:
          - ./Data/prometheus.yml:/etc/prometheus/prometheus.yml:ro
        command:
          - '--config.file=/etc/prometheus/prometheus.yml'

    grafana:
        image: grafana/grafana:11.1.4
        container_name: grafana
        hostname: grafana
        restart: unless-stopped
        ports:
          - 3000:3000
        environment:
            GF_SECURITY_ADMIN_PASSWORD: admin
            GF_AUTH_ANONYMOUS_ENABLED: true
            GF_AUTH_ANONYMOUS_ORG_ROLE: Admin
            GF_AUTH_DISABLE_LOGIN_FORM: true
        volumes:
          - ./Data/grafana:/var/lib/grafana
          - ./Data/grafana/provisioning:/etc/grafana/provisioning
        depends_on:
          - prometheus
          - loki

    loki:
        image: grafana/loki:main
        container_name: loki
        hostname: loki
        restart: unless-stopped
        ports:
          - 3100:3100
        command: -config.file=/etc/loki/local-config.yaml
        environment:
            JAEGER_AGENT_HOST: jaeger
            JAEGER_AGENT_PORT: 6831
            JAEGER_SAMPLER_TYPE: const
            JAEGER_SAMPLER_PARAM: 1
        healthcheck:
          test: wget -q --tries=1 -O- http://localhost:3100/ready
          interval: 3s
          timeout: 3s
          retries: 10
          start_period: 10s

    # https://github.com/jaegertracing/jaeger/blob/main/examples/grafana-integration/docker-compose.yaml
    jaeger:
        image: jaegertracing/all-in-one:1.60
        restart: unless-stopped
        container_name: jaeger
        hostname: jaeger
        ports:
          - 6831:6831/udp # UDP port for Jaeger agent
          - 16686:16686 # Web UI
          - 14268:14268 # HTTP port for spans
          - 14250:14250 # GRPC port for Jaeger agent

    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
        container_name: elasticsearch
        hostname: elasticsearch
        restart: unless-stopped
        # user: root
        environment:
          network.host: 0.0.0.0
          transport.host: 127.0.0.1
          discovery.type: single-node
          bootstrap.memory_lock: true
          xpack.security.enabled: false
          xpack.security.http.ssl.enabled: false
          xpack.monitoring.collection.enabled: false
          ingest.geoip.downloader.enabled: false
          logger.org.elasticsearch: ERROR
          logger.com.azure.core: ERROR
          logger.org.apache: ERROR
          ES_JAVA_OPTS: -Xms1g -Xmx1g
          # ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:?error}
        volumes:
          - ./Data/elasticsearch/elasticsearch-data:/usr/share/elasticsearch/data
          - ./Data/elasticsearch/conf.yml:/usr/share/elasticsearch/config/elasticsearch.yml
          - ./Data/elasticsearch/logs:/usr/share/elasticsearch/logs
        ports:
          - 9200:9200
        ulimits:
          memlock:
            soft: -1
            hard: -1
          nproc:
            soft: 65536
            hard: 65536
          nofile:
            soft: 65536
            hard: 65536
        cap_add:
          - IPC_LOCK
        healthcheck:
          test:
            [
              "CMD-SHELL",
              "curl --fail --silent http://localhost:9200/_cluster/health",
            ]
          interval: 10s
          timeout: 10s
          retries: 120


# https://gist.github.com/gschmutz/db582679c07c11f645b8cb9718e31209
# https://github.com/confluentinc/cp-all-in-one/blob/7.7.0-post/cp-all-in-one/docker-compose.yml